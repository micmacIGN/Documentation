{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_satellite_epipolaire.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMTJPcqp40qLaoV/Yj9eW9Q"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"S-Qvqelv9Mez"},"source":["# The satellite-image-based surface reconstruction in `MicMac`, tuto #2\n","\n","This tutorial is a continuation of the tutorial [01_basic_satellite.ipynb](https://github.com/micmacIGN/Documentation/blob/master/TutoJupyter/01_satellite_basic.ipynb). In contrast to the first tutorial, here, we will do multi-view surface reconstruction using epipolar images. After setting-up MicMac and downloading the dataset, the pipeline is as follows:\n","  1. Tie-points extraction\n","  2. RPC-bundle adjustement\n","  3. Automated pipeline for surface reconstruction from N images:\n","\n","    3.1. ***Epipolar*** image resampling\n","\n","    3.2. Re-creation of ***RPC localisation*** corresponding to the epipolar images \n","\n","    3.3. ***N stereo image matchings*** in image geometry\n","\n","    3.4. ***Spatial similarity transformation*** of individual depth maps to a common frame\n","\n","    3.5. ***Fusion***\n","  \n","<center>\n","  <img src=\"https://drive.google.com/uc?id=14riCQR0tz5Qa3JrOtcDQgOLvZOBgO-LJ\" height=220pix/>\n","  <br> \n","</center>\n","<center> Figure. General overview of the workflow.</center>\n","\n","\n","\n","\n","*Contact: ewelina.rupnik(at)ign.fr*"]},{"cell_type":"markdown","metadata":{"id":"xFg_W-L6_IlI"},"source":["## Projet set-up"]},{"cell_type":"markdown","metadata":{"id":"Wo33d-Q-_RML"},"source":["### Download and compile MicMac & dependencies"]},{"cell_type":"code","metadata":{"id":"IMidEdRQ_U7f"},"source":["import os\n","from os.path import exists, join, basename, splitext\n","import numpy as np \n","import cv2\n","import matplotlib.pyplot as plt   \n","\n","Dependencies_install = True\n","MicMac_clone = True\n","MicMac_cmake = True \n","MicMac_build = True\n","\n","YOUR_PATH = '/content/'#MyDrive/micmac/satellites/'\n","!cd $YOUR_PATH\n","!pwd\n","\n","\n","if Dependencies_install:\n","  !apt update\n","  !apt install -y cmake\n","  !pip install dlib\n","  !apt-get install imagemagick proj-bin exiv2\n","  !pip install wget gdown\n","\n","if MicMac_clone:\n","  if not exists(YOUR_PATH+'micmac/'):\n","    git_repo_url = 'https://github.com/micmacIGN/micmac.git'\n","    !git clone $git_repo_url\n","\n","if MicMac_cmake:\n","  !cd micmac\n","  if not exists(YOUR_PATH+'micmac/build'):\n","    !mkdir $YOUR_PATH\"micmac/build\"\n","\n","  !cd $YOUR_PATH\"micmac/build\"\n","  !cmake $YOUR_PATH\"micmac\" -DBUILD_POISSON=OFF\n","\n","  if MicMac_build:\n","    !make install -j28"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-pFv3bBM_c6b"},"source":["### Add environmental variable & download the dataset\n","\n","The dataset consists of: \n","  * 4 images (tif)\n","  * 4 corresponding RPCs (xml)\n","  * `WGS84toUTM.xml` with the definition of a projection coordinate system (*proj4* format)"]},{"cell_type":"code","metadata":{"id":"kv3Ud2Nl_gv9"},"source":["import os\n","os.environ['PATH'] += \":/content/micmac/bin/\"\n","!echo $PATH\n","\n","# if you can see the commands printed to the screen, everything is OK\n","!mm3d"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X0BKoL8K_iyf"},"source":["# download data\n","dataset_url = 'https://drive.google.com/uc?id=18hmQL5kIqhcnR5ahp8IUsMZxLv7jvjgB' \n","!gdown $dataset_url -O \"satellite_data.tar.gz\" \n","\n","# unpack\n","if not exists(YOUR_PATH+'satellite_data'):\n","  !mkdir $YOUR_PATH'satellite_data'\n","!tar -xf satellite_data.tar.gz -C $YOUR_PATH'satellite_data'\n","%cd $YOUR_PATH'satellite_data'\n","\n","# utility functions to visualise tie-points\n","utils_url='https://drive.google.com/uc?id=1ATO1Nz_aXApxVnm6l7x1xappGXtcjuvp'\n","!gdown $utils_url -O \"mm3d_utils.py\"   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gx4Ynq75_maY"},"source":["## 1. Extract SIFT tie-points\n","\n","  - **computation strategy**: there exist several predefined *strategies* to compute tie-points: `Line`, `All`, `MulScale`, `File`. We will use the `All` strategy where tie-points are searched between all possible pairs. Refer to MicMac documentation for the other modes. \n","  - **image resolution**: tie-points extraction is very costly, and to limit the computation time we usually downsampled the images; in this example, indicate resolution of `-1` which means full-resolution images; otherwise, if set to, e.g., `2000`, the images will be downsampled such that the larger image dimension (typically the width) will have `2000` pixels; the other dimension will have a size that is proportionally smaller;\n","  - **ExpTxt=1**: the extracted tie-points will be saved in a text format (as opossed to the default dat format)\n","  - **results**: tie-points are stored in the `Homol` directory. For instance, tie-points correponding to image `Im1.tif` will be stored in `Homol/PastisIm1.tif/` directory. If `Im1.tif` overlaps with `Im2.tif` and `Im3.tif`, their tie-points will be stored in `Homol/PastisIm1.tif/Im2.tif.dat` and `Homol/PastisIm1.tif/Im3.tif.dat`, respectively. If you chose to export in the text format, the `dat` extension will be replaced with `txt`.\n","\n","\n","*Note: Intermediary results are stored in the `Pastis` directory. It takesa  significant amount of space and is not used at later processing stages, therefore you may delete it.*"]},{"cell_type":"code","metadata":{"id":"dRm3o3xa_pEc"},"source":["!mm3d Tapioca All .*tif -1 ExpTxt=1 @ExitOnBrkp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cIHQw4iu_rWx"},"source":["### Visualise tie-points\n","\n","Read any pair of images and visalise their tie-points."]},{"cell_type":"code","metadata":{"id":"81naIP4J_w4Z"},"source":["import mm3d_utils \n","\n","aIm1 = cv2.imread('TPMM_0435.tif',cv2.IMREAD_IGNORE_ORIENTATION)\n","aIm2 = cv2.imread('TPMM_0566.tif',cv2.IMREAD_IGNORE_ORIENTATION) \n"," \n","TPtsVec = mm3d_utils.ImportHom(\"Homol/PastisTPMM_0435.tif/TPMM_0566.tif.txt\") \n"," \n","mm3d_utils.plot_images([np.asarray(aIm1),np.asarray(aIm2)]) \n","mm3d_utils.plot_tiepts2(np.asarray(TPtsVec,dtype=float))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c3OHDU60_0_6"},"source":["## 2. RPC-bundle adjustment"]},{"cell_type":"markdown","metadata":{"id":"UQ35fp83_4qx"},"source":["### Read the RPCs in DIMAP format\n","\n","This function reads the DIMAP format RPCs and converts it to a *MicMac* format. Several parameters are specified here:\n","\n","  - `(.*).tif` this is the pattern of input images (note the dot preceding the star which is the posix convention)\n","\n","  - `\\$1.xml` is the corresponding pattern of RPC files; I use here a regular expression that associates the image name with its corresponding RPC file name; you may also run the command independently for each image if you're not familiar with regular expressions;\n","\n","  - `RPC-d0` is the directory name where the converted files will be stored; it will serve as input in the following step, i.e., the bundle adjustment;\n","\n","  - `Degre=0`, the degree of the polynomial correction;\n","\n","  By choosing a zero-degree polynomial we will correct the satellite's geolocalisation by modelling a 3D image shift; please refer to [Rupnik et al., 2016] for more on the method.\n","\n","  - `ChSys=WGS84toUTM.xml` definition of the projection coordinate sytem; MicMac expects that the processing coordinate frame is euclidean and all three coordinates have the same unit. The RPCs are expressed in geographical coordinates which are neither euclidean, nor unique in terms of units. To overcome that, MicMac will transfer, on the fly, the RPCs to a user-defined coordinate system, in this exemple defined in the `WGS84toUTM.xml` file. The definition of the coordinate system follows the `proj4` library convention. You can retrieve the code corresponding to the coordinate frame of your interest from `https://spatialreference.org/`\n","\n","\n","\n","<sub> Rupnik, E., Deseilligny, M.P., Delorme, A. and Klinger, Y., 2016. Refined satellite image orientation in the free open-source photogrammetric tools Apero/Micmac. ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 3, p.83.<sub>"]},{"cell_type":"code","metadata":{"id":"pi-7e-z8_5r5"},"source":["!mm3d Convert2GenBundle -help @ExitOnBrkp\n","!mm3d Convert2GenBundle \"(.*).tif\" \"\\$1.xml\" RPC-d0 ChSys=WGS84toUTM.xml Degre=0  @ExitOnBrkp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kYBoDmoe_9Rl"},"source":["### Run the adjustment\n","\n","Within the bundle adjustemnt, MicMac will estimate the parameters of $D_x$ and $D_y$ functions, that are the polynomials you have defined in `Convert2GenBundle` method. In this example our observations are the tie-points. It is also possible to include ground control points.\n","\n","\n","$\\begin{equation}\n","\\begin{split}\n","y = g (\\phi, \\lambda, h) +  {D_y (x,y)}\\\\\n","x = h (\\phi, \\lambda, h) +  {D_x (x,y)}\n","\\end{split}\n","\\end{equation}$\n","\n","where $g$ and $h$ are the RPC functions, and \n","\n","$\\begin{equation}\n","\\begin{split}\n","D_y (x,y) = \\sum_{i=0}^m \\sum_{j=0}^n a_{ij} \\cdot x^i y^j \\\\\n","D_x (x,y) = \\sum_{i=0}^m \\sum_{j=0}^n b_{ij} \\cdot x^i y^j\n","\\end{split}\n","\\end{equation}$\n","\n","\n","The input parameters:\n","- `RPC-d0` is the folder with the initial geolocalisation\n","- `RPC-d0_adj` is the folder where the adjusted geoloc is saved\n","- `ExpTxt=1` indicates that tie-points are stored in text format "]},{"cell_type":"code","metadata":{"id":"HCNA1RTnACWe"},"source":["!mm3d Campari \".*tif\" RPC-d0 RPC-d0-adj ExpTxt=1 @ExitOnBrkp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xky5fPjGAA4s"},"source":["### Interpreting the results\n","\n","One way to asses the quality of the adjustment is to look at the tie-points residuals (for more sophisticated quality estimates see `MMTestOrient` in MicMac documentation). \n","\n","The bundle adjustment is carried out in several iterations. Let's look at image `TPMM_0435.tif` in the last iteration:\n","\n","> `RES:[TPMM_0435.tif][g] ER2 0.24636 Nn 100 Of 11753 Mul 5171 Mul-NN 5171 Time 1.15821`\n","\n","* `0.24636` pixels is the mean residual calculated over all tie-points (i.e., $\\sigma$ of the bundle)  \n","\n","* `Nn 100` means that 100$\\%$ of tie-points were considered as inliers\n","\n","* `11753` there were as many tie-points found\n","\n","* `5171` there were as many multiple tie-points found (out of the `11753`), i.e., tie-points observed in at least 3 images;"]},{"cell_type":"markdown","metadata":{"id":"Pd18W0GRE_UM"},"source":["## Automated pipeline for surface reconstruction"]},{"cell_type":"markdown","metadata":{"id":"7j6RvvvVAGKM"},"source":["### Compute the surface\n","\n","<center>\n","  <img src=\"https://drive.google.com/uc?id=1LgLh9rw4yW3VZqKiIFnBp8B8SszODuQq\" height=220pix/>\n","  <br> \n","</center>\n","<center> Figure. SAT4Geo pipeline.</center>\n","<br>\n","\n","The pipeline runs with `mm3d SAT4Geo` and consists of several sub-modules:\n","  - `SAT4Geo_Pairs` defines image pairs for which the image matching will be later computed; the result is stored in *Pairs.xml*; there are two $criteria$ applied when selecting pairs:  \n","      -  $\\frac{B}{H}$ range is set by default to   $\\in \\left< 0.01, 0.3 \\right>$; this range can be modified with the `BH` parameter;\n","      - images must overlap.\n","\n","    You may as well skip that step and provide the pipeline with your own pairs. To do that, put your pairs in the *xml* format file MicMac likes, and use the `Pairs` parameter, for instance `Pairs=YourOwnPairs.xml`\n","      \n","\n","  - `SAT4Geo_CreateEpip` creates epipolar images for a set of pairs defined in  *Pairs.xml*; it implements the approach presented in [1]\n","\n","  - `SAT4Geo_EpiRPC` calculates RPC functions for the images in their new geometry (i.e., epipolar geometry); by default the new RPCs are stored in `Ori-EpiRPC`\n","\n","  - `SAT4Geo_MM1P` carries out image matching for all image pairs in *Pairs.xml*; if your epipolar images were created outside MicMac, put their names inside the *xml* and MicMac shall know how to proceed; however, note that unless you provide the RPC files corresponding to your pairs, MicMac will not be able to perform the latter fusion;\n","      * the per-pair depth maps are found in seperate directories following this naming convention - `MEC-Cple_X_Y/`; their respective names are also stored in  `PairsDirMEC.xml`;\n","\n","\n","  - `SAT4Geo_Fuse` fuses the per-epipolar-pair depth maps into a single and (hopefully) complete surface; it is the xact same algorithm that was described in  [01_basic_satellite.ipynb](https://github.com/micmacIGN/Documentation/blob/master/TutoJupyter/01_satellite_basic.ipynb)\n","\n","    * The result is saved to `Fusion/Fusion_Prof.tif`, there is a corresponding mask and a correlation map named with `_Mask` and `Correl` postfixes, respectively.\n","\n","\n","\n","If you're interested in tweaking default parameters' values, type `-help`. In this `mm3d SAT4Geo` example, the parameters are:\n","\n","* `.*tif` is the pattern of input images\n","* `RPC-d0-adj` is the name of the directory with the RPCs (prefixed by `Ori-`)\n","* `ChSys=WGS84toUTM.xml` indicates the file that defines the processing coordinate frame\n","* `NbP=24` is the number of parallel processes (make sure it's less than the number of cores your PC has)\n","\n","\n","\n","<sub> [1] Marc Pierrot Deseilligny \\& Ewelina Rupnik. Epipolar rectification of a generic camera. 2020. ⟨hal-02968078⟩ \n","\n"," "]},{"cell_type":"code","metadata":{"id":"8j3707MYANDL"},"source":["# the Exe=0 means \"no execution\" but display commands that would be otherwise launched\n","!mm3d SAT4Geo \".*tif\" RPC-d0-adj ChSys=WGS84toUTM.xml NbP=24 Exe=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LQurtKqlAfQB"},"source":["!mm3d SAT4Geo \".*tif\" RPC-d0-adj ChSys=WGS84toUTM.xml NbP=24 Exe=1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aoi5pOnQcyQr"},"source":["### Create a grayshaded DSM\n","\n","Represent the surface in form of a grayshading. To visually asses the quality of your surface, it is much more intuitive than just looking at the depth/Z image. "]},{"cell_type":"code","metadata":{"id":"8C-Ds5WecynH"},"source":["!mm3d GrShade Fusion/Fusion_Prof.tif ModeOmbre=IgnE Mask=Fusion/Fusion_Masq.tif @ExitOnBrkp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"waeMwFN8dE6_"},"source":["### Visualise the grayshaded surface"]},{"cell_type":"code","metadata":{"id":"s2H5Szz6dFE1"},"source":["surface_shade_im = cv2.imread(\"Fusion/Fusion_ProfShade.tif\",cv2.IMREAD_IGNORE_ORIENTATION)\n","\n","fig, ax = plt.subplots(figsize=(30, 10))\n","ax.imshow(surface_shade_im,cmap=\"gray\") \n","plt.tight_layout()"],"execution_count":null,"outputs":[]}]}
